#!/usr/bin/env python3
"""
üöÄ –ê–í–¢–û–ù–û–ú–ù–´–ô –¢–û–†–ì–û–í–´–ô –ë–û–¢ v3.1
–ü–æ–ª–Ω–∞—è —Å–≤–æ–±–æ–¥–∞ –¥–µ–π—Å—Ç–≤–∏–π + —á–µ—Å—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–≥—Ä–∞–¥
"""

import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd
import ccxt
import time
import os
import signal
from datetime import datetime
from typing import Dict, Tuple, Optional
import json

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è RL
from stable_baselines3 import SAC
from stable_baselines3.common.buffers import ReplayBuffer
import torch
import torch.nn as nn

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ config.py
from config import Config
from dataclasses import dataclass
from typing import List


@dataclass
class Trade:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å–¥–µ–ª–∫–∏"""
    entry_price: float
    entry_time: int
    position_size: float  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ BTC
    trade_type: str  # 'LONG' –∏–ª–∏ 'SHORT'
    stop_loss: float = 0.0
    take_profit: float = 0.0
    # –ù–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–¥–µ–ª–∫–∏
    had_stop_loss: bool = False  # –ë—ã–ª –ª–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏
    had_take_profit: bool = False  # –ë—ã–ª –ª–∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏
    max_unrealized_profit: float = 0.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
    min_unrealized_loss: float = 0.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —É–±—ã—Ç–æ–∫
    # –°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤
    min_hold_steps: int = 0  # –ú–∏–Ω–∏–º—É–º —à–∞–≥–æ–≤ –¥–ª—è —É–¥–µ—Ä–∂–∞–Ω–∏—è
    steps_held: int = 0  # –°–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ —É–∂–µ –¥–µ—Ä–∂–∏–º


class TradeTracker:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π"""

    def __init__(self):
        self.active_trades: List[Trade] = []
        self.closed_trades: List[Dict] = []
        self.consecutive_wins = 0
        self.consecutive_losses = 0
        self.total_commission_paid = 0.0
        
        # –ù–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏
        self.trades_with_risk_management = 0  # –°–¥–µ–ª–∫–∏ —Å–æ —Å—Ç–æ–ø-–ª–æ—Å—Å–æ–º/—Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–æ–º
        self.stopped_out_trades = 0  # –°–¥–µ–ª–∫–∏ –∑–∞–∫—Ä—ã—Ç—ã–µ –ø–æ —Å—Ç–æ–ø-–ª–æ—Å—Å—É
        self.take_profit_trades = 0  # –°–¥–µ–ª–∫–∏ –∑–∞–∫—Ä—ã—Ç—ã–µ –ø–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—É
        self.manual_close_trades = 0  # –°–¥–µ–ª–∫–∏ –∑–∞–∫—Ä—ã—Ç—ã–µ –≤—Ä—É—á–Ω—É—é

    def open_trade(self, entry_price: float, position_size: float,
                   trade_type: str, stop_loss: float = 0.0, take_profit: float = 0.0) -> Trade:
        """–û—Ç–∫—Ä—ã—Ç—å –Ω–æ–≤—É—é —Å–¥–µ–ª–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —É—á–µ—Ç–æ–º —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞"""
        # –ï—Å–ª–∏ –µ—Å—Ç—å RM, —Ç—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 5 —à–∞–≥–æ–≤ —É–¥–µ—Ä–∂–∞–Ω–∏—è
        min_hold = 5 if (stop_loss > 0 or take_profit > 0) else 0

        trade = Trade(
            entry_price=entry_price,
            entry_time=int(time.time()),
            position_size=position_size,
            trade_type=trade_type,
            stop_loss=stop_loss,
            take_profit=take_profit,
            had_stop_loss=(stop_loss > 0),
            had_take_profit=(take_profit > 0),
            min_hold_steps=min_hold,
            steps_held=0
        )
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
        if stop_loss > 0 or take_profit > 0:
            self.trades_with_risk_management += 1
        
        self.active_trades.append(trade)
        return trade

    def update_unrealized_pnl(self, current_price: float):
        """–û–±–Ω–æ–≤–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫ –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–æ–∫"""
        for trade in self.active_trades:
            if trade.trade_type == 'LONG':
                unrealized_pnl = (current_price - trade.entry_price) / trade.entry_price
            else:  # SHORT
                unrealized_pnl = (trade.entry_price - current_price) / trade.entry_price

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º—ã
            trade.max_unrealized_profit = max(trade.max_unrealized_profit, unrealized_pnl)
            trade.min_unrealized_loss = min(trade.min_unrealized_loss, unrealized_pnl)

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ —É–¥–µ—Ä–∂–∞–Ω–∏—è
            trade.steps_held += 1

    def close_trade(self, exit_price: float, commission: float = 0.0, 
                   reason: str = 'manual') -> Dict:
        """–ó–∞–∫—Ä—ã—Ç—å —Å–¥–µ–ª–∫—É —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –ø—Ä–∏—á–∏–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è"""
        if not self.active_trades:
            return {}

        trade = self.active_trades.pop(0)  # FIFO
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º PnL
        if trade.trade_type == 'LONG':
            pnl = trade.position_size * (exit_price - trade.entry_price)
        else:  # SHORT
            pnl = trade.position_size * (trade.entry_price - exit_price)
        
        pnl_percent = pnl / (trade.position_size * trade.entry_price) * 100
        pnl_after_commission = pnl - commission
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø—É –∑–∞–∫—Ä—ã—Ç–∏—è
        if reason == 'stop_loss':
            self.stopped_out_trades += 1
        elif reason == 'take_profit':
            self.take_profit_trades += 1
        else:
            self.manual_close_trades += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Ä–∏–∏
        if pnl_after_commission > 0:
            self.consecutive_wins += 1
            self.consecutive_losses = 0
        else:
            self.consecutive_losses += 1
            self.consecutive_wins = 0
        
        self.total_commission_paid += commission
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤
        contract_violated = (trade.steps_held < trade.min_hold_steps and
                           reason == 'manual' and
                           abs(pnl_percent) < 5.0)  # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–≤–∏–∂–µ–Ω–∏–π

        trade_result = {
            'pnl': pnl,
            'pnl_percent': pnl_percent,
            'pnl_after_commission': pnl_after_commission,
            'duration': int(time.time()) - trade.entry_time,
            'entry_price': trade.entry_price,
            'exit_price': exit_price,
            'commission': commission,
            'position_size': trade.position_size,
            'trade_type': trade.trade_type,
            'close_reason': reason,
            'had_risk_management': trade.had_stop_loss or trade.had_take_profit,
            'max_unrealized_profit': trade.max_unrealized_profit,
            'min_unrealized_loss': trade.min_unrealized_loss,
            'gave_back_profit': trade.max_unrealized_profit - pnl_percent/100,  # –°–∫–æ–ª—å–∫–æ –ø—Ä–∏–±—ã–ª–∏ —É–ø—É—Å—Ç–∏–ª–∏
            'steps_held': trade.steps_held,
            'min_hold_required': trade.min_hold_steps,
            'contract_violated': contract_violated
        }
        
        self.closed_trades.append(trade_result)
        return trade_result

    def get_unrealized_pnl(self, current_price: float) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫"""
        total_unrealized = 0.0
        for trade in self.active_trades:
            if trade.trade_type == 'LONG':
                unrealized = trade.position_size * (current_price - trade.entry_price)
            else:
                unrealized = trade.position_size * (trade.entry_price - current_price)
            total_unrealized += unrealized
        return total_unrealized
    
    def get_risk_management_quality(self) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞ (0-1)"""
        if not self.closed_trades:
            return 0.0
        
        total_trades = len(self.closed_trades)
        
        # –§–∞–∫—Ç–æ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞
        rm_ratio = self.trades_with_risk_management / max(1, total_trades)
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç —Å–¥–µ–ª–æ–∫ –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—É (—Ö–æ—Ä–æ—à–æ)
        tp_ratio = self.take_profit_trades / max(1, total_trades)
        
        # –°—Ä–µ–¥–Ω—è—è —É–ø—É—â–µ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å (–ø–ª–æ—Ö–æ –µ—Å–ª–∏ –±–æ–ª—å—à–∞—è)
        avg_gave_back = np.mean([t.get('gave_back_profit', 0) for t in self.closed_trades[-10:]])
        gave_back_penalty = max(0, min(1, 1 - avg_gave_back * 10))  # –®—Ç—Ä–∞—Ñ –∑–∞ —É–ø—É—â–µ–Ω–Ω—É—é –ø—Ä–∏–±—ã–ª—å
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        quality = (rm_ratio * 0.3 + tp_ratio * 0.3 + gave_back_penalty * 0.4)
        return min(1.0, max(0.0, quality))


class TradingEnvironment(gym.Env):
    """
    –¢–æ—Ä–≥–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å —á–µ—Å—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π –Ω–∞–≥—Ä–∞–¥
    """

    def __init__(self, initial_balance: float = 10000, detailed_logging: bool = True):
        super().__init__()

        self.initial_balance = initial_balance
        self.detailed_logging = detailed_logging

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º - –ø–æ–ª–Ω–∞—è —Å–≤–æ–±–æ–¥–∞
        self.action_space = spaces.Box(
            low=np.array([
                -1.0,   # position_ratio: -100% (sell all) to +100% (buy all)
                0.0,    # stop_loss_pct: 0% to 20%
                0.0,    # take_profit_pct: 0% to 50%
            ]),
            high=np.array([
                1.0,    # position_ratio
                0.2,    # stop_loss_pct (max 20%)
                0.5,    # take_profit_pct (max 50%)
            ]),
            dtype=np.float32
        )

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π (30 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –±–æ–ª—å—à–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏)
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(30,), dtype=np.float32
        )

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._init_exchange()
        self._init_state()

    def _init_exchange(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Binance"""
        try:
            self.exchange = ccxt.binance({
                'apiKey': Config.API_KEY,
                'secret': Config.API_SECRET,
                'enableRateLimit': True,
                'options': {
                    'defaultType': 'spot'
                }
            })
            self.exchange.set_sandbox_mode(True)
            markets = self.exchange.load_markets()
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω –∫ Binance Testnet, –¥–æ—Å—Ç—É–ø–Ω–æ {len(markets)} —Ä—ã–Ω–∫–æ–≤")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Binance: {e}")
            print("üìä –†–∞–±–æ—Ç–∞–µ–º –≤ —Ä–µ–∂–∏–º–µ —Å–∏–º—É–ª—è—Ü–∏–∏")
            self.exchange = None

    def _init_state(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        self.balance = self.initial_balance
        self.btc_amount = 0.0
        self.current_price = 0.0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_trades = 0
        self.total_profit_loss = 0.0
        self.max_drawdown = 0.0
        self.peak_value = self.initial_balance
        
        # –ò—Å—Ç–æ—Ä–∏—è
        self.price_history = []
        self.action_history = []
        
        # –¢—Ä–µ–∫–µ—Ä —Å–¥–µ–ª–æ–∫
        self.trade_tracker = TradeTracker()
        
        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–∞–≥—Ä–∞–¥—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        self.last_reward_breakdown = {
            'trade_result': 0.0,
            'holding_penalty': 0.0,
            'risk_reward': 0.0,
            'efficiency': 0.0
        }

    def reset(self, seed: Optional[int] = None) -> Tuple[np.ndarray, Dict]:
        """–°–±—Ä–æ—Å –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        super().reset(seed=seed)
        self._init_state()
        self._update_market_data()
        return self._get_observation(), {}

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, bool, Dict]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        prev_portfolio_value = self._get_portfolio_value()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self._update_market_data()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π PnL –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        self.trade_tracker.update_unrealized_pnl(self.current_price)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–æ–ø-–æ—Ä–¥–µ—Ä–∞
        closed_trades = self._check_and_execute_stops()
        
        # –ò—Å–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        new_trade_opened = self._execute_action(action)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–∞–≥—Ä–∞–¥—É
        current_portfolio_value = self._get_portfolio_value()
        reward = self._calculate_reward(
            prev_portfolio_value, 
            current_portfolio_value, 
            action,
            closed_trades,
            new_trade_opened
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._update_statistics(current_portfolio_value)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–µ–π—Å—Ç–≤–∏–π
        self.action_history.append(action)
        if len(self.action_history) > 100:
            self.action_history = self.action_history[-100:]
        
        # –£—Å–ª–æ–≤–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        terminated = False  # –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–≤–µ—Ä—à–∞–µ–º
        truncated = current_portfolio_value < self.initial_balance * 0.05  # –ü—Ä–∏ –ø–æ—Ç–µ—Ä–µ 95%
        
        info = {
            'portfolio_value': current_portfolio_value,
            'btc_amount': self.btc_amount,
            'current_price': self.current_price,
            'active_trades': len(self.trade_tracker.active_trades),
            'total_trades': self.total_trades,
            'win_rate': len([t for t in self.trade_tracker.closed_trades if t['pnl_after_commission'] > 0]) / max(1, len(self.trade_tracker.closed_trades)),
            'roi': (current_portfolio_value - self.initial_balance) / self.initial_balance,
            'risk_management_quality': self.trade_tracker.get_risk_management_quality(),
            'reward_breakdown': self.last_reward_breakdown.copy()
        }
        
        return self._get_observation(), reward, terminated, truncated, info

    def _execute_action(self, action: np.ndarray) -> bool:
        """
        –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –æ—Ç–∫—Ä—ã—Ç–∞ –Ω–æ–≤–∞—è —Å–¥–µ–ª–∫–∞
        """
        position_ratio, stop_loss_pct, take_profit_pct = action

        if self.current_price <= 0:
            if self.detailed_logging:
                print(f"‚ö´ SKIP: Invalid price ${self.current_price:.2f}")
            return False

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
        portfolio_value = self._get_portfolio_value()

        # –ü–û–ö–£–ü–ö–ê (LONG)
        if position_ratio > 0.05:  # –ú–∏–Ω–∏–º—É–º 5% –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
            max_buy_amount = min(self.balance, portfolio_value * abs(position_ratio))

            if max_buy_amount <= 50:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è —Å—É–º–º–∞
                if self.detailed_logging:
                    print(f"‚ö´ SKIP BUY: ${max_buy_amount:.2f} < $50 minimum | Pos:{position_ratio:+.2f}")
                return False

            btc_to_buy = max_buy_amount / self.current_price
            commission = max_buy_amount * 0.001

            if max_buy_amount + commission > self.balance:
                if self.detailed_logging:
                    print(f"‚ö´ SKIP BUY: Need ${max_buy_amount + commission:.2f}, have ${self.balance:.2f}")
                return False

            # –ò—Å–ø–æ–ª–Ω—è–µ–º –ø–æ–∫—É–ø–∫—É
            self.balance -= (max_buy_amount + commission)
            self.btc_amount += btc_to_buy
            self.total_trades += 1

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É—Ä–æ–≤–Ω–∏ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞ –∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞
            sl_price = self.current_price * (1 - stop_loss_pct) if stop_loss_pct > 0.005 else 0
            tp_price = self.current_price * (1 + take_profit_pct) if take_profit_pct > 0.005 else 0

            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Å–¥–µ–ª–∫—É –≤ —Ç—Ä–µ–∫–µ—Ä–µ
            self.trade_tracker.open_trade(
                entry_price=self.current_price,
                position_size=btc_to_buy,
                trade_type='LONG',
                stop_loss=sl_price,
                take_profit=tp_price
            )

            self.trade_tracker.total_commission_paid += commission

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¥–µ—Ç–∞–ª—è–º–∏ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
            risk_info = ""
            if sl_price > 0:
                risk_info += f" SL@${sl_price:.2f}(-{stop_loss_pct*100:.1f}%)"
            if tp_price > 0:
                risk_info += f" TP@${tp_price:.2f}(+{take_profit_pct*100:.1f}%)"

            print(f"üü¢ LONG: {btc_to_buy:.6f} BTC @ ${self.current_price:.2f}{risk_info}")
            return True

        # –ü–†–û–î–ê–ñ–ê (–∑–∞–∫—Ä—ã—Ç–∏–µ –ø–æ–∑–∏—Ü–∏–∏)
        elif position_ratio < -0.05:
            if self.btc_amount <= 0:
                if self.detailed_logging:
                    print(f"‚ö´ SKIP SELL: No BTC to sell | Pos:{position_ratio:+.2f}")
                return False

            sell_ratio = min(abs(position_ratio), 1.0)
            btc_to_sell = min(self.btc_amount, self.btc_amount * sell_ratio)

            if btc_to_sell <= 0.0001:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–ª—è –ø—Ä–æ–¥–∞–∂–∏
                if self.detailed_logging:
                    print(f"‚ö´ SKIP SELL: {btc_to_sell:.6f} BTC < 0.0001 minimum")
                return False

            sell_amount = btc_to_sell * self.current_price
            commission = sell_amount * 0.001

            # –ò—Å–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–¥–∞–∂—É
            self.balance += (sell_amount - commission)
            self.btc_amount -= btc_to_sell
            self.total_trades += 1

            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å–¥–µ–ª–∫–∏ –≤ —Ç—Ä–µ–∫–µ—Ä–µ
            trades_to_close = int(len(self.trade_tracker.active_trades) * sell_ratio)
            if trades_to_close == 0 and len(self.trade_tracker.active_trades) > 0:
                trades_to_close = 1

            closed_info = []
            for _ in range(min(trades_to_close, len(self.trade_tracker.active_trades))):
                trade_result = self.trade_tracker.close_trade(
                    exit_price=self.current_price,
                    commission=commission / max(1, trades_to_close),
                    reason='manual'
                )
                if trade_result:
                    closed_info.append(trade_result)

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            if closed_info:
                avg_pnl = np.mean([t['pnl_percent'] for t in closed_info])
                print(f"üî¥ CLOSE {len(closed_info)} trades @ ${self.current_price:.2f} | Avg PnL: {avg_pnl:+.2f}%")

            return False  # –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –Ω–æ–≤–æ–π —Å–¥–µ–ª–∫–∏

        # HOLD - –Ω–∏–∫–∞–∫–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π
        else:
            if self.detailed_logging:
                print(f"‚ö™ HOLD @ ${self.current_price:.2f} | Pos:{position_ratio:+.2f} SL:{stop_loss_pct:.1%} TP:{take_profit_pct:.1%}")
            return False

    def _check_and_execute_stops(self) -> List[Dict]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ç–æ–ø-–æ—Ä–¥–µ—Ä–æ–≤"""
        closed_trades = []
        
        if not self.trade_tracker.active_trades:
            return closed_trades
        
        trades_to_close = []
        
        for i, trade in enumerate(self.trade_tracker.active_trades):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
            if trade.stop_loss > 0 and self.current_price <= trade.stop_loss:
                trades_to_close.append((i, 'stop_loss'))
                print(f"üõë STOP LOSS triggered @ ${self.current_price:.2f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞
            elif trade.take_profit > 0 and self.current_price >= trade.take_profit:
                trades_to_close.append((i, 'take_profit'))
                print(f"üéØ TAKE PROFIT triggered @ ${self.current_price:.2f}")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏–µ –æ—Ä–¥–µ—Ä–∞ (–≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ —á—Ç–æ–±—ã –Ω–µ —Å–±–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã)
        for idx, reason in reversed(trades_to_close):
            trade = self.trade_tracker.active_trades[idx]
            
            # –ü—Ä–æ–¥–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —á–∞—Å—Ç—å BTC
            if self.btc_amount >= trade.position_size:
                sell_amount = trade.position_size * self.current_price
                commission = sell_amount * 0.001
                
                self.balance += (sell_amount - commission)
                self.btc_amount -= trade.position_size
                
                # –£–¥–∞–ª—è–µ–º –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                self.trade_tracker.active_trades.pop(idx)
                trade_result = self.trade_tracker.close_trade(
                    exit_price=self.current_price,
                    commission=commission,
                    reason=reason
                )
                
                if trade_result:
                    closed_trades.append(trade_result)
                    self.total_trades += 1
        
        return closed_trades

    def _calculate_reward(self, prev_value: float, current_value: float,
                         action: np.ndarray, closed_trades: List[Dict],
                         new_trade_opened: bool) -> float:
        """
        –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ù–ê–ì–†–ê–î v2.0
        –ù–∞–≥—Ä–∞–¥—ã —Ç–æ–ª—å–∫–æ –∑–∞ –†–ï–ó–£–õ–¨–¢–ê–¢–´, —à—Ç—Ä–∞—Ñ—ã –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
        """
        total_reward = 0.0
        self.last_reward_breakdown = {
            'trade_result': 0.0,
            'contract_penalty': 0.0,
            'discipline_bonus': 0.0,
            'efficiency': 0.0
        }

        # 1. –ù–ê–ì–†–ê–î–ê –ó–ê –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ó–ê–ö–†–´–¢–´–• –°–î–ï–õ–û–ö
        if closed_trades:
            for trade in closed_trades:
                pnl_percent = trade['pnl_percent']

                # –ë–∞–∑–æ–≤–∞—è –Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ (–±–µ–∑ –±–æ–Ω—É—Å–æ–≤ –∑–∞ RM!)
                if pnl_percent > 0:
                    if pnl_percent > 5:
                        trade_reward = 200
                    elif pnl_percent > 2:
                        trade_reward = 100
                    elif pnl_percent > 1:
                        trade_reward = 50
                    else:
                        trade_reward = 20
                else:
                    if pnl_percent < -5:
                        trade_reward = -200
                    elif pnl_percent < -2:
                        trade_reward = -100
                    elif pnl_percent < -1:
                        trade_reward = -50
                    else:
                        trade_reward = -20

                # –®–¢–†–ê–§ –ó–ê –ù–ê–†–£–®–ï–ù–ò–ï –ö–û–ù–¢–†–ê–ö–¢–ù–´–• –û–ë–Ø–ó–ê–¢–ï–õ–¨–°–¢–í!
                if trade['contract_violated']:
                    violation_penalty = -50  # –°–µ—Ä—å–µ–∑–Ω—ã–π —à—Ç—Ä–∞—Ñ –∑–∞ –¥–æ—Å—Ä–æ—á–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ
                    trade_reward += violation_penalty
                    self.last_reward_breakdown['contract_penalty'] += violation_penalty
                    print(f"‚ö†Ô∏è CONTRACT VIOLATED: Closed after {trade['steps_held']}/{trade['min_hold_required']} steps ‚Üí {violation_penalty}")

                # –ë–û–ù–£–° –ó–ê –î–ò–°–¶–ò–ü–õ–ò–ù–£ - —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º—É –ø–ª–∞–Ω—É!
                if trade['close_reason'] in ['stop_loss', 'take_profit']:
                    discipline_bonus = 50  # –ë–æ–ª—å—à–∞—è –Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–ª–∞–Ω—É
                    trade_reward += discipline_bonus
                    self.last_reward_breakdown['discipline_bonus'] += discipline_bonus
                    print(f"üéñÔ∏è DISCIPLINE BONUS: {trade['close_reason'].upper()} executed as planned ‚Üí +{discipline_bonus}")

                self.last_reward_breakdown['trade_result'] += trade_reward
                total_reward += trade_reward

        # 2. –ë–ï–ó –§–ò–ö–¢–ò–í–ù–´–• –ù–ê–ì–†–ê–î –ó–ê –û–¢–ö–†–´–¢–ò–ï! ‚úÖ

        # 3. –®–¢–†–ê–§ –ó–ê –•–ê–û–¢–ò–ß–ù–£–Æ –¢–û–†–ì–û–í–õ–Æ (–∞–Ω—Ç–∏-–∫–∞—Ä—É—Å–µ–ª—å)
        if new_trade_opened and len(self.trade_tracker.closed_trades) > 0:
            last_trade = self.trade_tracker.closed_trades[-1]

            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–¥–µ–ª–∫–∞ –±—ã–ª–∞ –∑–∞–∫—Ä—ã—Ç–∞ –Ω–µ–¥–∞–≤–Ω–æ –±–µ–∑ –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã
            if (last_trade['steps_held'] < 3 and
                abs(last_trade['pnl_percent']) < 0.1):  # –ü–æ—á—Ç–∏ –Ω–æ–ª—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç

                carousel_penalty = -0.10
                total_reward += carousel_penalty
                self.last_reward_breakdown['efficiency'] += carousel_penalty
                print(f"üé† CAROUSEL PENALTY: Quick open‚Üíclose‚Üíopen pattern ‚Üí {carousel_penalty}")

        # 4. –®–¢–†–ê–§ –ó–ê –£–î–ï–†–ñ–ê–ù–ò–ï –£–ë–´–¢–û–ß–ù–´–• –ü–û–ó–ò–¶–ò–ô –ë–ï–ó –ó–ê–©–ò–¢–´
        if self.trade_tracker.active_trades:
            for trade in self.trade_tracker.active_trades:
                current_pnl = (self.current_price - trade.entry_price) / trade.entry_price

                # –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è —É–±—ã—Ç–æ—á–Ω–∞—è –∏ –Ω–µ—Ç —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
                if current_pnl < -0.03 and trade.stop_loss == 0:
                    unprotected_penalty = -20
                    total_reward += unprotected_penalty
                    self.last_reward_breakdown['efficiency'] += unprotected_penalty

        # 5. –ú–Ø–ì–ö–ò–ô –°–ò–ì–ù–ê–õ –û–ë –ò–ó–ú–ï–ù–ï–ù–ò–ò –ü–û–†–¢–§–ï–õ–Ø (—Å–∏–ª—å–Ω–æ —É–º–µ–Ω—å—à–µ–Ω)
        portfolio_change = (current_value - prev_value) / self.initial_balance
        total_reward += portfolio_change * 5  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 10 –¥–æ 5

        return total_reward

    def _update_market_data(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if self.exchange:
                ticker = self.exchange.fetch_ticker('BTC/USDT')
                self.current_price = ticker['last']
            else:
                # –°–∏–º—É–ª—è—Ü–∏—è —Ü–µ–Ω—ã
                if len(self.price_history) == 0:
                    self.current_price = 67000.0
                else:
                    # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                    returns = np.random.normal(0, 0.001)  # 0.1% —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
                    self.current_price = self.current_price * (1 + returns)
            
            self.price_history.append(self.current_price)
            if len(self.price_history) > 100:
                self.price_history = self.price_history[-100:]
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            if self.current_price <= 0:
                self.current_price = 67000.0

    def _get_portfolio_value(self) -> float:
        """–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        return self.balance + (self.btc_amount * self.current_price)

    def _get_observation(self) -> np.ndarray:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤–ª–∏"""
        obs = []
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ü–µ–Ω–µ
        obs.append(self.current_price / 100000)  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞
        
        # –¢—Ä–µ–Ω–¥ —Ü–µ–Ω—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        if len(self.price_history) >= 6:
            for i in range(1, 6):
                change = (self.price_history[-i] - self.price_history[-i-1]) / self.price_history[-i-1]
                obs.append(change * 100)  # –£—Å–∏–ª–∏–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª
        else:
            obs.extend([0] * 5)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        portfolio_value = self._get_portfolio_value()
        obs.extend([
            self.balance / self.initial_balance - 1,
            (self.btc_amount * self.current_price) / self.initial_balance if self.current_price > 0 else 0,
            (portfolio_value - self.initial_balance) / self.initial_balance,
        ])
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–∫–∞—Ö
        obs.append(len(self.trade_tracker.active_trades) / 10)  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        
        if self.trade_tracker.active_trades:
            # –°—Ä–µ–¥–Ω–∏–π –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π PnL
            unrealized_pnls = []
            for trade in self.trade_tracker.active_trades:
                pnl = (self.current_price - trade.entry_price) / trade.entry_price
                unrealized_pnls.append(pnl)
            obs.append(np.mean(unrealized_pnls))
            
            # –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–∑–∏—Ü–∏–π —Å —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–æ–º
            rm_positions = sum(1 for t in self.trade_tracker.active_trades if t.had_stop_loss or t.had_take_profit)
            obs.append(rm_positions / len(self.trade_tracker.active_trades))
        else:
            obs.extend([0, 0])
        
        # –ò—Å—Ç–æ—Ä–∏—è —Ç–æ—Ä–≥–æ–≤–ª–∏
        if self.trade_tracker.closed_trades:
            recent_trades = self.trade_tracker.closed_trades[-5:]
            
            # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–¥–µ–ª–æ–∫
            avg_pnl = np.mean([t['pnl_percent'] for t in recent_trades]) / 100
            obs.append(avg_pnl)
            
            # Win rate –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–¥–µ–ª–æ–∫
            wins = sum(1 for t in recent_trades if t['pnl_after_commission'] > 0)
            obs.append(wins / len(recent_trades))
            
            # –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
            obs.append(self.trade_tracker.get_risk_management_quality())
        else:
            obs.extend([0, 0, 0])
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        if len(self.price_history) >= 20:
            # SMA
            sma_5 = np.mean(self.price_history[-5:])
            sma_20 = np.mean(self.price_history[-20:])
            obs.extend([
                self.current_price / sma_5 - 1,
                self.current_price / sma_20 - 1,
                sma_5 / sma_20 - 1,
            ])
            
            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            returns = []
            for i in range(1, 20):
                ret = (self.price_history[-i] - self.price_history[-i-1]) / self.price_history[-i-1]
                returns.append(ret)
            volatility = np.std(returns)
            obs.append(volatility * 100)  # –£—Å–∏–ª–∏–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª
        else:
            obs.extend([0, 0, 0, 0])
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–µ–π—Å—Ç–≤–∏–π (–ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å —Å–≤–æ–π —Å—Ç–∏–ª—å)
        if len(self.action_history) >= 5:
            recent_actions = self.action_history[-5:]
            
            # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π
            avg_position = np.mean([a[0] for a in recent_actions])
            avg_sl = np.mean([a[1] for a in recent_actions])
            avg_tp = np.mean([a[2] for a in recent_actions])
            
            obs.extend([avg_position, avg_sl, avg_tp])
        else:
            obs.extend([0, 0, 0])
        
        # –†—ã–Ω–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        obs.extend([
            self.trade_tracker.consecutive_wins / 10,
            self.trade_tracker.consecutive_losses / 10,
            self.max_drawdown,
        ])
        
        # –î–æ–ø–æ–ª–Ω—è–µ–º –¥–æ 30 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        while len(obs) < 30:
            obs.append(0.0)
        
        return np.array(obs[:30], dtype=np.float32)

    def _update_statistics(self, current_value: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if current_value > self.peak_value:
            self.peak_value = current_value
        
        drawdown = (self.peak_value - current_value) / self.peak_value
        if drawdown > self.max_drawdown:
            self.max_drawdown = drawdown


class TradingAgent:
    """SAC –∞–≥–µ–Ω—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º"""
    
    def __init__(self, env: TradingEnvironment, model_path: Optional[str] = None):
        self.env = env
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
        policy_kwargs = dict(
            activation_fn=nn.ReLU,  # ReLU —á–∞—Å—Ç–æ –ª—É—á—à–µ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            net_arch=dict(
                pi=[512, 256, 128],  # Policy network
                qf=[512, 256, 128]   # Q-function network
            )
        )
        
        if model_path and os.path.exists(model_path):
            self.model = SAC.load(model_path, env=env)
            print(f"üìÇ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
            self._load_buffer(model_path)
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            self.model = SAC(
                "MlpPolicy",
                env,
                learning_rate=0.0003,  # –ù–µ–º–Ω–æ–≥–æ –≤—ã—à–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
                buffer_size=100000,
                learning_starts=100,   # –ù–∞—á–∏–Ω–∞–µ–º —É—á–∏—Ç—å—Å—è —Ä–∞–Ω—å—à–µ
                batch_size=256,
                tau=0.005,
                gamma=0.99,
                train_freq=1,
                gradient_steps=1,
                verbose=0
            )
            print("üÜï –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π SAC –∞–≥–µ–Ω—Ç")
        
        self.step_count = 0
        self.learning_stats = {
            'total_updates': 0,
            'recent_rewards': [],
            'best_roi': -float('inf'),
            'recent_trade_results': []
        }

    def _load_buffer(self, model_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ replay buffer"""
        import pickle
        buffer_path = f"{model_path}_buffer.pkl"
        
        if os.path.exists(buffer_path):
            try:
                with open(buffer_path, 'rb') as f:
                    data = pickle.load(f)
                
                if 'replay_buffer' in data:
                    self.model.replay_buffer = data['replay_buffer']
                    print(f"üì¶ Replay buffer –∑–∞–≥—Ä—É–∂–µ–Ω: {self.model.replay_buffer.size()} –∑–∞–ø–∏—Å–µ–π")
                
                if 'step_count' in data:
                    self.step_count = data['step_count']
                
                if 'learning_stats' in data:
                    self.learning_stats = data['learning_stats']
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ buffer: {e}")

    def predict(self, observation: np.ndarray, deterministic: bool = False) -> np.ndarray:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        action, _states = self.model.predict(observation, deterministic=deterministic)
        return action

    def learn_online(self, obs: np.ndarray, action: np.ndarray,
                    reward: float, next_obs: np.ndarray, done: bool):
        """–û–Ω–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ"""
        self.step_count += 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ replay buffer
        self.model.replay_buffer.add(obs, next_obs, action, reward, done, [{}])
        
        # –û–±—É—á–∞–µ–º—Å—è –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–ø—ã—Ç–∞
        if self.model.replay_buffer.size() >= self.model.learning_starts:
            try:
                if not hasattr(self.model, '_logger'):
                    from stable_baselines3.common.logger import configure
                    self.model._logger = configure(folder=None, format_strings=[])
                
                self.model.train(gradient_steps=1)
                self.learning_stats['total_updates'] += 1
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è
                if reward > 50:
                    print(f"üéØ –û–±—É—á–µ–Ω–∏–µ #{self.learning_stats['total_updates']} | –û–¢–õ–ò–ß–ù–û–ï –¥–µ–π—Å—Ç–≤–∏–µ: +{reward:.1f}")
                elif reward > 0:
                    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ #{self.learning_stats['total_updates']} | –•–æ—Ä–æ—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ: +{reward:.1f}")
                elif reward < -50:
                    print(f"‚ùå –û–±—É—á–µ–Ω–∏–µ #{self.learning_stats['total_updates']} | –ü–ª–æ—Ö–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {reward:.1f}")
                
                # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ 20 –æ–±—É—á–µ–Ω–∏–π
                if self.learning_stats['total_updates'] % 20 == 0:
                    self._log_learning_progress()
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.learning_stats['recent_rewards'].append(reward)
        if len(self.learning_stats['recent_rewards']) > 100:
            self.learning_stats['recent_rewards'] = self.learning_stats['recent_rewards'][-100:]

    def save(self, path: str = "./models/trading_bot"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        self.model.save(path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º replay buffer
        import pickle
        buffer_path = f"{path}_buffer.pkl"
        try:
            with open(buffer_path, 'wb') as f:
                pickle.dump({
                    'replay_buffer': self.model.replay_buffer,
                    'step_count': self.step_count,
                    'learning_stats': self.learning_stats
                }, f)
            print(f"üíæ –ú–æ–¥–µ–ª—å –∏ buffer —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è buffer: {e}")

    def _log_learning_progress(self):
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        if not self.learning_stats['recent_rewards']:
            return
        
        recent_rewards = self.learning_stats['recent_rewards'][-20:]
        avg_reward = np.mean(recent_rewards)
        positive_rewards = sum(1 for r in recent_rewards if r > 0)
        
        print(f"""
üìä –ü–†–û–ì–†–ï–°–° –û–ë–£–ß–ï–ù–ò–Ø (#{self.learning_stats['total_updates']}):
‚îú‚îÄ üìà –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {avg_reward:+.1f}
‚îú‚îÄ ‚úÖ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {positive_rewards}/20 ({positive_rewards*5}%)
‚îú‚îÄ üì¶ Buffer size: {self.model.replay_buffer.size()}
‚îî‚îÄ üéØ –õ—É—á—à–∏–π ROI: {self.learning_stats.get('best_roi', 0):.2%}
        """)


class AutonomousTradingBot:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –±–æ—Ç–∞"""
    
    def __init__(self):
        print("""
üöÄ –ê–í–¢–û–ù–û–ú–ù–´–ô –¢–û–†–ì–û–í–´–ô –ë–û–¢ v3.1
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üí∞ –ë–∞–ª–∞–Ω—Å: $10,000
üéØ –°–∏—Å—Ç–µ–º–∞ –Ω–∞–≥—Ä–∞–¥: –ó–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –Ω–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
üß† –ò–ò: SAC —Å –ø–æ–ª–Ω–æ–π —Å–≤–æ–±–æ–¥–æ–π
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        """)
        
        self.env = TradingEnvironment(Config.INITIAL_BALANCE, detailed_logging=True)
        
        model_path = "./models/trading_bot.zip"
        if os.path.exists(model_path):
            self.agent = TradingAgent(self.env, model_path)
        else:
            self.agent = TradingAgent(self.env)
        
        self.running = False
        self.start_time = None
        self.total_steps = 0
        
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def start_trading(self):
        """–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏"""
        print("\nüöÄ –ó–ê–ü–£–°–ö –ê–í–¢–û–ù–û–ú–ù–û–ô –¢–û–†–ì–û–í–õ–ò!")
        print("üìå –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n")
        
        self.running = True
        self.start_time = time.time()
        
        obs, _ = self.env.reset()
        
        try:
            while self.running:
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ –æ—Ç –ò–ò
                action = self.agent.predict(obs, deterministic=False)
                
                # –ò—Å–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
                next_obs, reward, terminated, truncated, info = self.env.step(action)
                
                # –û–ë–£–ß–ê–ï–ú–°–Ø –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ
                self.agent.learn_online(obs, action, reward, next_obs, terminated or truncated)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                self._log_step(info, action, reward)
                
                # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
                obs = next_obs
                self.total_steps += 1
                
                # –°–±—Ä–æ—Å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                if terminated or truncated:
                    print("üîÑ –°–±—Ä–æ—Å –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
                    obs, _ = self.env.reset()
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤
                if self.total_steps % 100 == 0:
                    self.agent.save()
                
                # –ü–∞—É–∑–∞
              # 1 —Å–µ–∫—É–Ω–¥–∞ –º–µ–∂–¥—É —Ä–µ—à–µ–Ω–∏—è–º–∏
                
        except KeyboardInterrupt:
            print("\n‚è∏Ô∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞...")
        finally:
            self._shutdown()

    def _log_step(self, info: Dict, action: np.ndarray, reward: float):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        if self.total_steps % 10 == 0:
            current_time = datetime.now().strftime("%H:%M:%S")
            portfolio = info['portfolio_value']
            roi = info['roi'] * 100
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
            action_str = f"Pos:{action[0]:+.2f}"
            if action[1] > 0.005:
                action_str += f" SL:{action[1]:.1%}"
            if action[2] > 0.005:
                action_str += f" TP:{action[2]:.1%}"
            
            # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã
            reward_details = info.get('reward_breakdown', {})
            reward_str = f"{reward:+.1f}"
            if reward_details:
                components = []
                if reward_details.get('trade_result', 0) != 0:
                    components.append(f"Trade:{reward_details['trade_result']:+.0f}")
                if reward_details.get('contract_penalty', 0) != 0:
                    components.append(f"Contract:{reward_details['contract_penalty']:+.0f}")
                if reward_details.get('discipline_bonus', 0) != 0:
                    components.append(f"Discipline:{reward_details['discipline_bonus']:+.0f}")
                if reward_details.get('efficiency', 0) != 0:
                    components.append(f"Efficiency:{reward_details['efficiency']:+.0f}")

                if components:
                    reward_str += f" ({' | '.join(components)})"
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π ROI
            current_roi = info['roi']
            if current_roi > self.agent.learning_stats['best_roi']:
                self.agent.learning_stats['best_roi'] = current_roi

            print(f"""
[{current_time}] üìä –®–∞–≥ {self.total_steps}
‚îú‚îÄ üí∞ –ü–æ—Ä—Ç—Ñ–µ–ª—å: ${portfolio:,.2f} (ROI: {roi:+.2f}%)
‚îú‚îÄ üéØ –î–µ–π—Å—Ç–≤–∏–µ: {action_str}
‚îú‚îÄ üèÜ –ù–∞–≥—Ä–∞–¥–∞: {reward_str}
‚îú‚îÄ üìà –°–¥–µ–ª–æ–∫: {info['total_trades']} (WR: {info['win_rate']:.1%})
‚îú‚îÄ üìç –ê–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π: {info['active_trades']}
‚îú‚îÄ üéñÔ∏è –ö–∞—á–µ—Å—Ç–≤–æ RM: {info['risk_management_quality']:.1%}
‚îî‚îÄ üß† –û–±—É—á–µ–Ω–∏–π: {self.agent.learning_stats['total_updates']}
            """)

    def _signal_handler(self, signum, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        print(f"\n‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
        print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å...")
        
        try:
            self.agent.save()
            print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        
        self.running = False

    def _shutdown(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        print("\nüõë –ó–ê–í–ï–†–®–ï–ù–ò–ï –†–ê–ë–û–¢–´")
        
        self.agent.save()
        
        runtime = time.time() - self.start_time if self.start_time else 0
        final_value = self.env._get_portfolio_value()
        total_roi = (final_value - self.env.initial_balance) / self.env.initial_balance * 100
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–¥–µ–ª–æ–∫
        closed_trades = self.env.trade_tracker.closed_trades
        if closed_trades:
            profitable = sum(1 for t in closed_trades if t['pnl_after_commission'] > 0)
            avg_profit = np.mean([t['pnl_percent'] for t in closed_trades if t['pnl_after_commission'] > 0]) if profitable > 0 else 0
            avg_loss = np.mean([t['pnl_percent'] for t in closed_trades if t['pnl_after_commission'] <= 0]) if profitable < len(closed_trades) else 0
            
            rm_trades = sum(1 for t in closed_trades if t['had_risk_management'])
            tp_exits = sum(1 for t in closed_trades if t['close_reason'] == 'take_profit')
            sl_exits = sum(1 for t in closed_trades if t['close_reason'] == 'stop_loss')
        else:
            profitable = avg_profit = avg_loss = rm_trades = tp_exits = sl_exits = 0
        
        print(f"""
üìà –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚è±Ô∏è  –í—Ä–µ–º—è: {runtime/3600:.2f} —á–∞—Å–æ–≤
üî¢ –®–∞–≥–æ–≤: {self.total_steps}
üí∞ –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: ${final_value:,.2f}
üìä ROI: {total_roi:+.2f}%
üìà –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {len(closed_trades)}
üèÜ Win Rate: {profitable/max(1, len(closed_trades)):.1%}
üíö –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å: {avg_profit:+.1f}%
üíî –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫: {avg_loss:.1f}%
üõ°Ô∏è –°–¥–µ–ª–æ–∫ —Å RM: {rm_trades} ({rm_trades/max(1, len(closed_trades)):.1%})
üéØ –ó–∞–∫—Ä—ã—Ç–æ –ø–æ TP: {tp_exits}
üõë –ó–∞–∫—Ä—ã—Ç–æ –ø–æ SL: {sl_exits}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        """)
        
        print("üëã –î–æ –≤—Å—Ç—Ä–µ—á–∏!")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    bot = AutonomousTradingBot()
    bot.start_trading()


if __name__ == "__main__":
    main()
