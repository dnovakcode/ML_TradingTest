#!/usr/bin/env python3
"""
test_bot.py - –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –±–æ—Ç–∞ –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏
"""

import numpy as np
from main import TradingEnvironment, TradingAgent


def test_environment():
    """–¢–µ—Å—Ç –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    
    env = TradingEnvironment(10000)
    obs, _ = env.reset()
    
    print(f"‚úÖ Observation shape: {obs.shape}")
    print(f"‚úÖ Action space: {env.action_space}")
    
    # –¢–µ—Å—Ç —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
    total_reward = 0
    for i in range(10):
        action = env.action_space.sample()
        obs, reward, term, trunc, info = env.step(action)
        total_reward += reward
        
        print(f"–®–∞–≥ {i+1}: reward={reward:.1f}, portfolio=${info['portfolio_value']:.2f}")
        
    print(f"üéØ –û–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {total_reward:.1f}")
    return True


def test_agent():
    """–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞"""
    print("\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞...")
    
    env = TradingEnvironment(10000)
    agent = TradingAgent(env)
    
    obs, _ = env.reset()
    
    for i in range(5):
        action = agent.predict(obs)
        obs, reward, term, trunc, info = env.step(action)
        
        print(f"–®–∞–≥ {i+1}: action={action}, reward={reward:.1f}")
        
    print("‚úÖ –ê–≥–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    return True


if __name__ == "__main__":
    print("üöÄ –¢–ï–°–¢ –¢–û–†–ì–û–í–û–ì–û –ë–û–¢–ê")
    print("="*40)
    
    # –¢–µ—Å—Ç 1: –û–∫—Ä—É–∂–µ–Ω–∏–µ
    test_environment()
    
    # –¢–µ—Å—Ç 2: –ê–≥–µ–Ω—Ç
    test_agent()
    
    print("\n‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
    print("üéØ –ó–∞–ø—É—Å–∫–∞–π—Ç–µ: python main.py")
